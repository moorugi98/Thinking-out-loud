<h1 id="autopoietic-enactivism-and-teleological-explanation">Autopoietic Enactivism and teleological Explanation</h1>

<h2 id="minseok-kang">Minseok Kang</h2>

<h3 id="introduction">Introduction</h3>

<p>In this article, I introduce enactivism which characterises autonomy as a necessary condition for cognition. To do so, we will draw insights from Heidegger’s notion of being-in-the-world as the transcendental mode of being. Understanding the relationship between autonomy and cognition will enable us to view life and mind as two continuous phenomena, which is the thesis that is often put forward by enactivists. Lastly, adaptivity will be introduced as an additional necessary condition for cognition. Also, check out <a href="https://cognitivesciencesociety.org/paradigm-shifts-in-cognitive-science/">the article</a> that I wrote for the cognitive science society, which can serve as an easy introduction to the topic.</p>

<h3 id="definition">Definition</h3>

<p>Enactivism refers to a school of thought which argues that cognition emerges by an interaction between an organism (cogniser) and its environment (world). According to enactivists, a cogniser finds itself always inside its world of significance, and this world is brought forth by the cogniser’s particular way of interacting with the environment. This way of conceptualising cognition has to do with its distinctive emphasis on the agency. What is it that makes agency such an important characteristic? To understand this, we will need to understand Heidegger’s critique of Cartesianism and rationalistic philosophy in general.</p>

<h3 id="heidegger">Heidegger</h3>

<p>Before I introduce Heidegger’s philosophy, let us briefly turn our attention to the history of artificial intelligence (AI). As cognitive science emerged as a coherent interdisciplinary discipline to study the mind and its processes in the ’50s, AI researchers focused on systems that were based on rules and symbol manipulation. Although these systems performed well in their expert domains, Hubert Dreyfus criticised that this sort of AI wouldn’t be able to show flexible and context-specific behaviours like human [4]. For him, misleading assumptions of Cartesian philosophy was at the core of the problem. Cartesianism influenced cognitive science from the start without being thoroughly examined. In Cartesianism, subject and object are thought to be of two fundamentally different entities. The world in which a cogniser finds itself is characterised in terms of its physical existence, which doesn’t depend on how or whether the cogniser perceives it. The cogniser as a subject gains knowledge about the world when her internal representation of the world matches to the real state of the outside world. Crucially, the subject is therefore thought to be located outside of the world that she is trying to get a grasp of [3].</p>

<p>This is exactly the point which is criticised by Martin Heidegger. Heidegger uses the term being-in-the-world which serves as an alternative of terms such as subject and object [9]. Being-in-the-world is the transcendental mode of human being which makes all other modes of human being intelligible.  When we are skilfully acting upon solicitations of the environment, we do not recognise ourselves as cogniser in our experience. Even in the case of breakdown of equipment, which means that the equipment presents itself as an object with facts related to it and not as a tool, being-in-the-world is at the background to make this kind of abstract understanding possible. As Dreyfus puts it, “in our most basic way of being, that is, as absorbed skilful copers, we are not minds at all but one with the world” [4]. It is thus impossible for us to step out of the world of significance and view it in a value-neutral way. To be precise, even saying that we cannot step outside the world is wrong since there is no inside and outside. In terms of experience, <strong>every situation matters for us</strong> as each situation invites us to act in certain ways. It is this mattering that fundamentally distinguishes a cogniser from a non-cogniser.</p>

<h3 id="justifying-teleology">Justifying Teleology</h3>

<p>We now understand on the basis of Heideggerian philosophy why having a meaningful perspective on the world is necessary for any entities to be considered cognitive. Let us now further investigate how we can differentiate entities with a meaningful perspective from those that do not. To have a meaningful perspective on the world is to have a <strong>preference</strong> that is <strong>internally generated</strong>. Froese asks us to consider the difference between a human and a thermostat to explain the difference between internally generated goals and externally imposed goals [1]. Both are systems that can register states of their environments and manipulate them to achieve their goals. However, most would agree that we don’t want to consider a thermostat as an autonomous agent, whereas in the case of a human we would want to do so. In the case of human, it seems reasonable to attribute an ability to generate its own goal to it. In comparison, the goal of a thermostat (i.e. to change its physical body accordingly to the current temperature) is a goal that is clearly imposed by the person who made it. The thermostat does not care whether it achieves its goal or not.</p>

<p>It is worth noting that just adding an extra value unit to a system is not sufficient for the system to have an internal goal because the <strong>experience</strong> of significance and mattering cannot be captured by adding the extra unit despite its success in replicating the function of significance.</p>

<p>One might now oppose that explaining behaviour of a system in terms of purposes and goals, i.e. <strong>teleology</strong>, is not necessary and that these descriptions can be reduced to causal statements. After all, it does seem misleading to describe a bacterium moving towards food in terms of the bacterium’s will. Isn’t it the case that the bacterium simply has a built-in sensorimotor loop to make its body move towards the food? However, according to Stuart Kauffman, it is impossible to get rid of teleology [7, p.131] because of the two following reasons. First, there is no way to define a finite subset of physical description that contributes meaningfully to a behaviour. In other words, one cannot distinguish which of physical descriptions is a meaningful one and which is just a confounding one that does not have anything to do with the behaviour to be described. Second, it is impossible to pre-define physical events that is equivalent to a description of the behaviour. He thus rejects a reductionistic explanation of behaviour and validates the necessity of usage of teleological description.</p>

<h3 id="autonomy">Autonomy</h3>

<p>As a next step, it would be useful to investigate how a system with an internal goal (e.g. human) can be differentiated from a system with an external goal (e.g. thermostat). Hans Jonas observes that a living organism must act to exist as such, which is not the case for an artificial system:</p>

<p>A feedback mechanism may be going, or may be at rest: in either state the machine exists. The organism has to keep going, because <strong>to be going is its very existence</strong> – which is revocable – and, threatened with extinction, it is concerned in existing [10, p. 126].</p>

<p>Jonas is thus proposing that only those systems which exist by doing can create their own identity. A living being achieves this through metabolism because it is generated and keep on existing only via a matter of metabolism. Stopping to metabolise will result in a diffusion of its bodily matter. Every living being is concerned with its existence and thus generates its own world of significance.  [11]</p>

<p><strong>Autopoiesis</strong>, introduced by Varela, captures important insights made by Jonas in a systematic and operationalised manner [12] :</p>

<p>an autopoietic system is organized (defined as a unity) as a network of processes of production (synthesis and destruction) of components such that these components:</p>
<ol>
  <li>continuously regenerate and realize the network that produces them, and 2. constitute the system as a distinguishable unity in the domain in which they exist [13].</li>
</ol>

<p>In other words, an autopoietic system must form a distinctive whole in contrast to its environment, and it must be able to maintain itself as such without any lending help from other external processes. Importantly, autopoiesis also generates its distinctive set of possible interactions between itself and its environment [1].</p>

<p>We now understand the connection between life and mind. Living beings generate their world of significance, which is a fundamental characteristic of cognitive beings in enactivism. However, we need a more general principle to include non-living beings that might be capable of generating a meaningful world. For this purpose, Varela proposes the concept of organisational closure which can account for <strong>constitutive autonomy</strong> in general, whereas autopoiesis was confined only to a biochemical domain [14, p. 55]. In short, an organisation which forms a distinctive unity with self-generating processes are said to be constitutively autonomous. Constitutive autonomy is then a necessary condition for intrinsic teleology, i.e. for a system to have an internally generated goal.</p>

<p>However, one might oppose at this point that it is unnecessary or even contradictory to view e.g.) a nervous system as being autonomous. The nervous system is embedded inside a body to perceive and act. Therefore it seems impossible that the nervous system is organisationally closed. Evan Thompson replies back with three arguments [5, p. 49 -51]. First, autonomy is a heuristical concept that should guide our scientific investigations. It is indeed <strong>possible to view every system as lacking autonomy</strong>. This does not mean that it is always helpful when it comes to understanding phenomena that are interesting to investigate. Second, the operation of the system as such must be distinguished from how it performs in a wider context. In the case of the nervous system, it is possible to characterise it as organisationally closed via recurrent connections between neurons. At the same time, one can acknowledge neuronal activities will depend on how the system interacted with the body and the environment. Lastly, by characterising an autonomous system as a system lacking autonomy, one is changing the system of interest. The nervous system that is defined in terms of the organism’s body needs to incorporate the body into the system as well, which is different from the nervous system as a neuronal network.</p>

<h3 id="sense-making">Sense-making</h3>

<p>Finally, I introduce adaptivity as another condition necessary for cognition. We start by acknowledging that the meaning of each encounter with an event cannot be found within the event itself. It is rather a relational property between an agent and its environment. More specifically, each encounter is evaluated in regard to its effect on the agent’s self-maintenance. As we saw before, to exist is the most basic concern for any agent that is constitutively autonomous. This generation of meaning by and for an agent is referred to as <strong>sense-making</strong> [11].</p>

<p>However, constitutive autonomy alone cannot provide a tool for a graded evaluation of an encounter in the world. It only provides a binary classifier, whereas an encounter stopping the agent to exist is a bad one. What is needed so that an agent can evaluate how good or bad each encounter is? Di Paolo proposed <strong>adaptivity</strong> as a concept that can be helpful to characterise an agent that can make sense of its world [15]. Adaptivity refers to an agent’s capacity to register changes in the environment, to evaluate these and to act appropriately to keep oneself in a favourable state. According to Di Paolo, “if autopoiesis in the present analysis suffices for generating a natural purpose, adaptivity reflects the organism’s capability – necessary for sense-making – of evaluating the needs and expanding the means towards that purpose” [15].</p>

<h3 id="summary">Summary</h3>

<p>I end the article by reviewing the main idea of the article. Enactivism proposes to view cognition as a relational phenomenon which depends on interactions between a system and its environment. Enactivism agrees with Heidegger that our view of cognition should be able to explain our experience as cognitive beings in the world, namely that we always find every situation mattering to us in a specific way. This led to capturing autonomy as a necessary condition for cognition. An autonomous system is characterised by its ability to create its own goal and the most basic goal conceivable is to exist. Living systems always have a goal to exist and this is achieved by a matter of continuous metabolism. To make a graded evaluation of each situation possible, the system needs to adapt to changes in its environment. On the final notice, I want to point out although autonomy and adaptivity are two necessary conditions for cognition, they need not be sufficient conditions. In other words, there might be additional conditions which require further investigations to fully account for cognition. I hold this for highly likely since very simple organisms such as yeast fulfil these two conditions, but a lot of us will feel uncomfortable to accept yeast as a cognitive being [16].</p>

<h3 id="reference">Reference</h3>

<p>[1] Froese, T., &amp; Ziemke, T. (2009). Enactive artificial intelligence: Investigating the systemic organization of life and mind. Artificial Intelligence, 173(3–4), 466–500. <a href="https://doi.org/10.1016/j.artint.2008.12.001">https://doi.org/10.1016/j.artint.2008.12.001</a></p>

<p>[2] Froese, T. (2007). On the role of AI in the ongoing paradigm shift within the cognitive sciences. Lecture Notes in Computer Science (Including Subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics). <a href="https://doi.org/10.1007/978-3-540-77296-5_7">https://doi.org/10.1007/978-3-540-77296-57</a></p>

<p>[3] Kiverstein, J., &amp; Wheeler, M. (2012). Heidegger and Cognitive Science. <a href="https://doi.org/10.1007/978-1-137-00610-3_1">https://doi.org/10.1007/978-1-137-00610-3_1</a></p>

<p>[4] Dreyfus, H. L. (2007). Why Heideggerian AI failed and how fixing it would require making it more Heideggerian. Artificial Intelligence, 171(18), 1137–1160. <a href="https://doi.org/10.1016/j.artint.2007.10.012">https://doi.org/10.1016/j.artint.2007.10.012</a></p>

<p>[5] Thompson, E. (2007). Mind in Life: Biology, Phenomenology, and the Sciences of Mind. In Phenomenology and the Cognitive Sciences. THE BELKNAP PRESS OF HARVARD UNIVERSITY PRESS. <a href="https://doi.org/10.1007/s11097-008-9114-2">https://doi.org/10.1007/s11097-008-9114-2</a></p>

<p>[6] Stendera, M. (2015). Being-in-the-World, Temporality and Autopoiesis. Parrhesia: A Journal of Critical Philosophy.</p>

<p>[7] Kauffman, S. (2008). Reinventing the sacred: a new view of science, reason, and religion. Brockman Inc.</p>

<p>[8] Ward, D., &amp; Stapleton, M. (2012). Es are good: Cognition as enacted, embodied, embedded, affective and extended. In F. Paglieri (Ed.), Consciousness in Interaction: The role of the natural and social context in shaping consciousness (pp. 89–104). John Benjamins.</p>

<p>[9] Heidegger, M., Macquarrie, J., &amp; Robinson, E. (1962). Being and time. Malden, MA: Blackwell.</p>

<p>[10] H. Jonas, The Phenomenon of Life: Toward a Philosophical Biology, Northwestern University Press, Evanston, IL, 2001</p>

<p>[11] A. Weber, F.J. Varela, Life after Kant: Natural purposes and the autopoietic foundations of biological individuality, Phenomenology and the Cognitive Sciences 1 (2002) 97–125.</p>

<p>[12] F.J. Varela, The early days of autopoiesis: Heinz and Chile, Systems Research 13 (3) (1996) 407–416.</p>

<p>[13] F.J. Varela, Organism: A meshwork of selfless selves, in: A.I. Tauber (Ed.), Organisms and the Origins of Self, Kluwer Academic Publishers, Dordrecht, Netherlands, 1991, pp. 79–107.</p>

<p>[14] F.J. Varela, Principles of Biological Autonomy, Elsevier North Holland, New York, NY, 1979.</p>

<p>[15] E.A. Di Paolo, Autopoiesis, adaptivity, teleology, agency, Phenomenology and the Cognitive Sciences 4 (4) (2005) 429–452.</p>

<p>[16] P. Moradas-Ferreira &amp; V. Costa (2000) Adaptive response of the yeast Saccharomyces cerevisiae to reactive oxygen species: defences, damage and death, Redox Report, 5:5, 277-285, DOI: 10.1179/135100000101535816</p>
